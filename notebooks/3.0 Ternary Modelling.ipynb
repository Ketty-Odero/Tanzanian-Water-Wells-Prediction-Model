{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TERNARY CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "The main metric to access my models' performance here is **Accuracy Score**. However, for this specific problem, we would also want to be able to identify non-operational waterpoints as well as those that are in need of repair early on, to help the Tanzanian Ministry of Water dispense resources accordingly. Therefore, I would also be looking at **Recall Score** particularly of the 2 classes `non functional` and `functional needs repair`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Feature selection and engineering\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model evaluation\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>status_group</th>\n",
       "      <th>year_recorded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>ROMAN</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>ROMAN</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>LAKE NYASA</td>\n",
       "      <td>IRINGA</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>ANNUALLY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>ENOUGH</td>\n",
       "      <td>GROUNDWATER</td>\n",
       "      <td>COMMUNAL STANDPIPE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>LAKE VICTORIA</td>\n",
       "      <td>MARA</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>NEVER PAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>INSUFFICIENT</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COMMUNAL STANDPIPE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>LOTTERY CLUB</td>\n",
       "      <td>686.0</td>\n",
       "      <td>WORLD VISION</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>PANGANI</td>\n",
       "      <td>MANYARA</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>PER BUCKET</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>ENOUGH</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COMMUNAL STANDPIPE MULTIPLE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>263.0</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>RUVUMA / SOUTHERN COAST</td>\n",
       "      <td>MTWARA</td>\n",
       "      <td>...</td>\n",
       "      <td>1986</td>\n",
       "      <td>SUBMERSIBLE</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>NEVER PAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>DRY</td>\n",
       "      <td>GROUNDWATER</td>\n",
       "      <td>COMMUNAL STANDPIPE MULTIPLE</td>\n",
       "      <td>NON FUNCTIONAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>ACTION IN A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ARTISAN</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>LAKE VICTORIA</td>\n",
       "      <td>KAGERA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NEVER PAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>SEASONAL</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COMMUNAL STANDPIPE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0    2011-03-14         ROMAN      1390.0         ROMAN   \n",
       "1   8776         0.0    2013-03-06       GRUMETI      1399.0       GRUMETI   \n",
       "2  34310        25.0    2013-02-25  LOTTERY CLUB       686.0  WORLD VISION   \n",
       "3  67743         0.0    2013-01-28        UNICEF       263.0        UNICEF   \n",
       "4  19728         0.0    2011-07-13   ACTION IN A         0.0       ARTISAN   \n",
       "\n",
       "   longitude   latitude                    basin   region  ...  \\\n",
       "0  34.938093  -9.856322               LAKE NYASA   IRINGA  ...   \n",
       "1  34.698766  -2.147466            LAKE VICTORIA     MARA  ...   \n",
       "2  37.460664  -3.821329                  PANGANI  MANYARA  ...   \n",
       "3  38.486161 -11.155298  RUVUMA / SOUTHERN COAST   MTWARA  ...   \n",
       "4  31.130847  -1.825359            LAKE VICTORIA   KAGERA  ...   \n",
       "\n",
       "  construction_year  extraction_type_class  management_group payment_type  \\\n",
       "0              1999                GRAVITY        USER-GROUP     ANNUALLY   \n",
       "1              2010                GRAVITY        USER-GROUP    NEVER PAY   \n",
       "2              2009                GRAVITY        USER-GROUP   PER BUCKET   \n",
       "3              1986            SUBMERSIBLE        USER-GROUP    NEVER PAY   \n",
       "4                 0                GRAVITY             OTHER    NEVER PAY   \n",
       "\n",
       "   quality_group      quantity source_class              waterpoint_type  \\\n",
       "0           GOOD        ENOUGH  GROUNDWATER           COMMUNAL STANDPIPE   \n",
       "1           GOOD  INSUFFICIENT      SURFACE           COMMUNAL STANDPIPE   \n",
       "2           GOOD        ENOUGH      SURFACE  COMMUNAL STANDPIPE MULTIPLE   \n",
       "3           GOOD           DRY  GROUNDWATER  COMMUNAL STANDPIPE MULTIPLE   \n",
       "4           GOOD      SEASONAL      SURFACE           COMMUNAL STANDPIPE   \n",
       "\n",
       "     status_group year_recorded  \n",
       "0      FUNCTIONAL          2011  \n",
       "1      FUNCTIONAL          2013  \n",
       "2      FUNCTIONAL          2013  \n",
       "3  NON FUNCTIONAL          2013  \n",
       "4      FUNCTIONAL          2011  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/wells_data_cleaned.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59400 entries, 0 to 59399\n",
      "Data columns (total 25 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   id                     59400 non-null  int64  \n",
      " 1   amount_tsh             59400 non-null  float64\n",
      " 2   date_recorded          59400 non-null  object \n",
      " 3   funder                 59400 non-null  object \n",
      " 4   gps_height             59400 non-null  float64\n",
      " 5   installer              59400 non-null  object \n",
      " 6   longitude              59400 non-null  float64\n",
      " 7   latitude               59400 non-null  float64\n",
      " 8   basin                  59400 non-null  object \n",
      " 9   region                 59400 non-null  object \n",
      " 10  lga                    59400 non-null  object \n",
      " 11  population             59400 non-null  int64  \n",
      " 12  public_meeting         59400 non-null  bool   \n",
      " 13  scheme_management      59400 non-null  object \n",
      " 14  permit                 59400 non-null  bool   \n",
      " 15  construction_year      59400 non-null  int64  \n",
      " 16  extraction_type_class  59400 non-null  object \n",
      " 17  management_group       59400 non-null  object \n",
      " 18  payment_type           59400 non-null  object \n",
      " 19  quality_group          59400 non-null  object \n",
      " 20  quantity               59400 non-null  object \n",
      " 21  source_class           59400 non-null  object \n",
      " 22  waterpoint_type        59400 non-null  object \n",
      " 23  status_group           59400 non-null  object \n",
      " 24  year_recorded          59400 non-null  int64  \n",
      "dtypes: bool(2), float64(4), int64(4), object(15)\n",
      "memory usage: 10.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 Data Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Splitting Data ###\n",
      "Training set size: 47520 rows\n",
      "Testing set size: 11880 rows\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Splitting the dataset\n",
    "def split_data():\n",
    "    print(\"\\n### Splitting Data ###\")\n",
    "    \n",
    "    # Separate features and target variable\n",
    "    X = df.drop(['id', 'date_recorded','status_group'], axis=1)  # Features/Input values/x\n",
    "    y = df['status_group']  # Target/Labels/Output\n",
    "    \n",
    "    # Splitting into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    print(f\"Training set size: {X_train.shape[0]} rows\")\n",
    "    print(f\"Testing set size: {X_test.shape[0]} rows\")\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 Encoding categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace problematic values with a default category\n",
    "X_train['funder'] = X_train['funder'].replace('RURAL WATER SUPPLY AND SANITAT', 'OTHER')\n",
    "X_test['funder'] = X_test['funder'].replace('RURAL WATER SUPPLY AND SANITAT', 'OTHER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def balanced_encoding(X_train, X_test):\n",
    "    print(\"\\n### Encoding Categorical and Boolean Columns with Balanced Approach ###\")\n",
    "\n",
    "    # Handle boolean columns (convert to integers)\n",
    "    bool_columns = X_train.select_dtypes(include=['bool']).columns\n",
    "    print(f\"Boolean columns: {list(bool_columns)}\")\n",
    "    for col in bool_columns:\n",
    "        X_train[col] = X_train[col].astype(int)\n",
    "        X_test[col] = X_test[col].astype(int)\n",
    "\n",
    "    # Identify categorical columns\n",
    "    categorical_columns = X_train.select_dtypes(include=['object']).columns\n",
    "    print(f\"Categorical columns: {list(categorical_columns)}\")\n",
    "\n",
    "    # Split into high and low-cardinality columns\n",
    "    high_cardinality_cols = [col for col in categorical_columns if X_train[col].nunique() > 10]\n",
    "    low_cardinality_cols = [col for col in categorical_columns if X_train[col].nunique() <= 10]\n",
    "\n",
    "    # Label Encoding for high-cardinality columns\n",
    "    label_encoders = {}\n",
    "    for col in high_cardinality_cols:\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = le.fit_transform(X_train[col])\n",
    "        X_test[col] = X_test[col].map(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
    "        label_encoders[col] = le  # Save encoder for later use\n",
    "\n",
    "    # One-Hot Encoding for low-cardinality columns\n",
    "    X_train = pd.get_dummies(X_train, columns=low_cardinality_cols, drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=low_cardinality_cols, drop_first=True)\n",
    "\n",
    "    # Align columns in train and test sets (handle dummy column mismatch)\n",
    "    X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n",
    "\n",
    "    print(\"Balanced encoding completed successfully.\")\n",
    "    return X_train, X_test, label_encoders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Encoding Categorical and Boolean Columns with Balanced Approach ###\n",
      "Boolean columns: ['public_meeting', 'permit']\n",
      "Categorical columns: ['funder', 'installer', 'basin', 'region', 'lga', 'scheme_management', 'extraction_type_class', 'management_group', 'payment_type', 'quality_group', 'quantity', 'source_class', 'waterpoint_type']\n",
      "Balanced encoding completed successfully.\n",
      "X_train_encoded shape: (47520, 55)\n",
      "X_test_encoded shape: (11880, 55)\n"
     ]
    }
   ],
   "source": [
    "# Apply the balanced encoding function\n",
    "X_train_encoded, X_test_encoded, label_encoders = balanced_encoding(X_train, X_test)\n",
    "\n",
    "# Verify the results\n",
    "print(\"X_train_encoded shape:\", X_train_encoded.shape)\n",
    "print(\"X_test_encoded shape:\", X_test_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Encoding Mapping:\n",
      "{'FUNCTIONAL': 0, 'FUNCTIONAL NEEDS REPAIR': 1, 'NON FUNCTIONAL': 2}\n",
      "Encoded y_train (first 5):\n",
      " 3607     0\n",
      "50870    0\n",
      "20413    2\n",
      "52806    2\n",
      "50091    2\n",
      "Name: status_group, dtype: int32\n",
      "Encoded y_test (first 5):\n",
      " 2980     2\n",
      "5246     0\n",
      "22659    0\n",
      "39888    2\n",
      "13361    0\n",
      "Name: status_group, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Initialize LabelEncoder\n",
    "label_encoder_y = LabelEncoder()\n",
    "\n",
    "# Fit and transform y_train, ensure it remains a Pandas Series\n",
    "y_train_encoded = pd.Series(\n",
    "    label_encoder_y.fit_transform(y_train),\n",
    "    index=y_train.index,\n",
    "    name=\"status_group\"\n",
    ")\n",
    "\n",
    "# Transform y_test, ensure it remains a Pandas Series\n",
    "y_test_encoded = pd.Series(\n",
    "    label_encoder_y.transform(y_test),\n",
    "    index=y_test.index,\n",
    "    name=\"status_group\"\n",
    ")\n",
    "\n",
    "# Print the mapping for reference\n",
    "print(\"Target Encoding Mapping:\")\n",
    "print(dict(zip(label_encoder_y.classes_, range(len(label_encoder_y.classes_)))))\n",
    "\n",
    "# Verify encoded values\n",
    "print(\"Encoded y_train (first 5):\\n\", y_train_encoded.head())\n",
    "print(\"Encoded y_test (first 5):\\n\", y_test_encoded.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 Scaling Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Identify numeric columns\n",
    "numeric_columns = X_train_encoded.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# Initialize scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale numeric columns\n",
    "X_train_encoded[numeric_columns] = scaler.fit_transform(X_train_encoded[numeric_columns])\n",
    "X_test_encoded[numeric_columns] = scaler.transform(X_test_encoded[numeric_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4 Fitting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_fix_encoding(X_train, X_test):\n",
    "    # Identify problematic columns\n",
    "    non_numeric_columns = X_train.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for col in non_numeric_columns:\n",
    "        print(f\"Encoding column: {col}\")\n",
    "        le = LabelEncoder()\n",
    "        X_train[col] = le.fit_transform(X_train[col].astype(str))\n",
    "        X_test[col] = X_test[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else -1)\n",
    "\n",
    "    return X_train, X_test\n",
    "\n",
    "X_train_encoded, X_test_encoded = check_and_fix_encoding(X_train_encoded, X_test_encoded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Train Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "log_reg.fit(X_train_encoded, y_train_encoded)\n",
    "y_pred_log_reg = log_reg.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train_encoded, y_train_encoded)\n",
    "y_pred_dec_tree = decision_tree.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train Random Forest\n",
    "random_forest = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "random_forest.fit(X_train_encoded, y_train_encoded)\n",
    "y_pred_rand_forest = random_forest.predict(X_test_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5 Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.85      0.76      6457\n",
      "           1       0.00      0.00      0.00       851\n",
      "           2       0.68      0.56      0.62      4572\n",
      "\n",
      "    accuracy                           0.68     11880\n",
      "   macro avg       0.45      0.47      0.46     11880\n",
      "weighted avg       0.63      0.68      0.65     11880\n",
      "\n",
      "\n",
      "Decision Tree Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80      6457\n",
      "           1       0.35      0.39      0.37       851\n",
      "           2       0.76      0.77      0.76      4572\n",
      "\n",
      "    accuracy                           0.75     11880\n",
      "   macro avg       0.64      0.65      0.64     11880\n",
      "weighted avg       0.76      0.75      0.75     11880\n",
      "\n",
      "\n",
      "Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84      6457\n",
      "           1       0.51      0.35      0.41       851\n",
      "           2       0.82      0.78      0.80      4572\n",
      "\n",
      "    accuracy                           0.80     11880\n",
      "   macro avg       0.71      0.67      0.68     11880\n",
      "weighted avg       0.79      0.80      0.79     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "print(\"Logistic Regression Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_log_reg))\n",
    "\n",
    "# Decision Tree\n",
    "print(\"\\nDecision Tree Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_dec_tree))\n",
    "\n",
    "# Random Forest\n",
    "print(\"\\nRandom Forest Report:\")\n",
    "print(classification_report(y_test_encoded, y_pred_rand_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Observations\n",
    "\n",
    "`Random Forest:`\n",
    "\n",
    "- Best overall performance with the highest accuracy (79%).\n",
    "- Performs well for Functional and Non Functional classes.\n",
    "- Struggles with the minority class Functional Needs Repair (Class 1), but slightly better than other models.\n",
    "\n",
    "`Logistic Regression:`\n",
    "\n",
    "- Performs poorly for Functional Needs Repair (Class 1) with 0% recall.\n",
    "- Handles Functional and Non Functional classes moderately well.\n",
    "\n",
    "`Decision Tree:`\n",
    "\n",
    "- Better balance between classes compared to Logistic Regression.\n",
    "- Recall for Functional Needs Repair (Class 1) is better (29%) but still needs improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score comparison between train and test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Comparison:\n",
      "                 Model  Training Accuracy  Test Accuracy\n",
      "0  Logistic Regression           0.684806       0.679882\n",
      "1        Decision Tree           0.996886       0.751768\n",
      "2        Random Forest           0.996801       0.799074\n"
     ]
    }
   ],
   "source": [
    "# Accuracy Comparisons\n",
    "# Logistic Regression Predictions\n",
    "y_train_pred_log_reg = log_reg.predict(X_train_encoded)\n",
    "y_test_pred_log_reg = log_reg.predict(X_test_encoded)\n",
    "\n",
    "# Decision Tree Predictions\n",
    "y_train_pred_dec_tree = decision_tree.predict(X_train_encoded)\n",
    "y_test_pred_dec_tree = decision_tree.predict(X_test_encoded)\n",
    "\n",
    "# Random Forest Predictions\n",
    "y_train_pred_rand_forest = random_forest.predict(X_train_encoded)\n",
    "y_test_pred_rand_forest = random_forest.predict(X_test_encoded)\n",
    "accuracy_data = {\n",
    "    \"Model\": [\"Logistic Regression\", \"Decision Tree\", \"Random Forest\"],\n",
    "    \"Training Accuracy\": [\n",
    "        accuracy_score(y_train_encoded, y_train_pred_log_reg),\n",
    "        accuracy_score(y_train_encoded, y_train_pred_dec_tree),\n",
    "        accuracy_score(y_train_encoded, y_train_pred_rand_forest),\n",
    "    ],\n",
    "    \"Test Accuracy\": [\n",
    "        accuracy_score(y_test_encoded, y_test_pred_log_reg),\n",
    "        accuracy_score(y_test_encoded, y_test_pred_dec_tree),\n",
    "        accuracy_score(y_test_encoded, y_test_pred_rand_forest),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Create a DataFrame for comparison\n",
    "accuracy_comparison = pd.DataFrame(accuracy_data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"\\nAccuracy Comparison:\")\n",
    "print(accuracy_comparison)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights\n",
    "\n",
    "`Logistic Regression:`\n",
    "\n",
    "The performance on the training and test sets is close, indicating the model is not overfitting. However, the overall accuracy is lower compared to the other models.\n",
    "\n",
    "`Decision Tree:`\n",
    "\n",
    "The significant gap between training and test accuracy indicates overfitting. The model is memorizing the training data but failing to generalize well on the test data.\n",
    "\n",
    "`Random Forest:`\n",
    "\n",
    "While the training accuracy is very high, the test accuracy is significantly better than the Decision Tree. The model still shows some signs of overfitting but generalizes better than the Decision Tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6 Class Balancing - correction for imbalance observed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: Counter({0: 25802, 2: 18252, 1: 3466})\n",
      "After SMOTE: Counter({0: 25802, 2: 25802, 1: 25802})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE on X_train_encoded and y_train_encoded\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# Print class distribution before and after\n",
    "print(\"Before SMOTE:\", Counter(y_train_encoded))\n",
    "print(\"After SMOTE:\", Counter(y_train_balanced))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refitting models with SMOTE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Refit models using the SMOTE-balanced data\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Decision Tree\n",
    "decision_tree.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Random Forest\n",
    "random_forest.fit(X_train_balanced, y_train_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.62      0.67      6457\n",
      "           1       0.15      0.46      0.23       851\n",
      "           2       0.69      0.56      0.62      4572\n",
      "\n",
      "    accuracy                           0.59     11880\n",
      "   macro avg       0.52      0.55      0.50     11880\n",
      "weighted avg       0.67      0.59      0.62     11880\n",
      "\n",
      "\n",
      "Decision Tree Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79      6457\n",
      "           1       0.34      0.45      0.39       851\n",
      "           2       0.76      0.75      0.75      4572\n",
      "\n",
      "    accuracy                           0.74     11880\n",
      "   macro avg       0.63      0.66      0.64     11880\n",
      "weighted avg       0.75      0.74      0.75     11880\n",
      "\n",
      "\n",
      "Random Forest Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.83      0.83      6457\n",
      "           1       0.40      0.45      0.42       851\n",
      "           2       0.81      0.79      0.80      4572\n",
      "\n",
      "    accuracy                           0.78     11880\n",
      "   macro avg       0.68      0.69      0.68     11880\n",
      "weighted avg       0.79      0.78      0.79     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predictions after SMOTE\n",
    "y_test_pred_log_reg = log_reg.predict(X_test_encoded)\n",
    "y_test_pred_dec_tree = decision_tree.predict(X_test_encoded)\n",
    "y_test_pred_rand_forest = random_forest.predict(X_test_encoded)\n",
    "\n",
    "# Classification Reports\n",
    "print(\"Logistic Regression Report:\")\n",
    "print(classification_report(y_test_encoded, y_test_pred_log_reg))\n",
    "\n",
    "print(\"\\nDecision Tree Report:\")\n",
    "print(classification_report(y_test_encoded, y_test_pred_dec_tree))\n",
    "\n",
    "print(\"\\nRandom Forest Report:\")\n",
    "print(classification_report(y_test_encoded, y_test_pred_rand_forest))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights from SMOTE data\n",
    "\n",
    "- Logistic Regression sees a drop in overall accuracy but better recall for minority classes.\n",
    "- Decision Tree improves slightly for minority classes but remains lower than Random Forest.\n",
    "- Random Forest maintains strong performance and gains improvements for minority class recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7 Hyperparameter Tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'max_depth': None,\n",
       "  'min_samples_leaf': 1,\n",
       "  'min_samples_split': 2,\n",
       "  'n_estimators': 200},\n",
       " 0.8481974512589772)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "}\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_weighted',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit GridSearchCV\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "best_params, best_score\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
