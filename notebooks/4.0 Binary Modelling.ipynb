{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARY CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Feature selection and engineering\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model evaluation\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of 'modules' to sys.path\n",
    "sys.path.append(os.path.abspath(\"../modules\"))\n",
    "\n",
    "# Now import\n",
    "from modules.EDA import EDA\n",
    "from modules.dataprocessor import DataProcessor\n",
    "from modules.testprocessor import TestDatasetProcessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>status_group</th>\n",
       "      <th>year_recorded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>ROMAN</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>ROMAN</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>LAKE NYASA</td>\n",
       "      <td>IRINGA</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>ANNUALLY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>ENOUGH</td>\n",
       "      <td>GROUNDWATER</td>\n",
       "      <td>COMMUNAL STANDPIPE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>LAKE VICTORIA</td>\n",
       "      <td>MARA</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>NEVER PAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>INSUFFICIENT</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COMMUNAL STANDPIPE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>LOTTERY CLUB</td>\n",
       "      <td>686.0</td>\n",
       "      <td>WORLD VISION</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>PANGANI</td>\n",
       "      <td>MANYARA</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>PER BUCKET</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>ENOUGH</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COMMUNAL STANDPIPE MULTIPLE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>263.0</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>RUVUMA / SOUTHERN COAST</td>\n",
       "      <td>MTWARA</td>\n",
       "      <td>...</td>\n",
       "      <td>1986</td>\n",
       "      <td>SUBMERSIBLE</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>NEVER PAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>DRY</td>\n",
       "      <td>GROUNDWATER</td>\n",
       "      <td>COMMUNAL STANDPIPE MULTIPLE</td>\n",
       "      <td>NON FUNCTIONAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>ACTION IN A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ARTISAN</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>LAKE VICTORIA</td>\n",
       "      <td>KAGERA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NEVER PAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>SEASONAL</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COMMUNAL STANDPIPE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0    2011-03-14         ROMAN      1390.0         ROMAN   \n",
       "1   8776         0.0    2013-03-06       GRUMETI      1399.0       GRUMETI   \n",
       "2  34310        25.0    2013-02-25  LOTTERY CLUB       686.0  WORLD VISION   \n",
       "3  67743         0.0    2013-01-28        UNICEF       263.0        UNICEF   \n",
       "4  19728         0.0    2011-07-13   ACTION IN A         0.0       ARTISAN   \n",
       "\n",
       "   longitude   latitude                    basin   region  ...  \\\n",
       "0  34.938093  -9.856322               LAKE NYASA   IRINGA  ...   \n",
       "1  34.698766  -2.147466            LAKE VICTORIA     MARA  ...   \n",
       "2  37.460664  -3.821329                  PANGANI  MANYARA  ...   \n",
       "3  38.486161 -11.155298  RUVUMA / SOUTHERN COAST   MTWARA  ...   \n",
       "4  31.130847  -1.825359            LAKE VICTORIA   KAGERA  ...   \n",
       "\n",
       "  construction_year  extraction_type_class management_group payment_type  \\\n",
       "0              1999                GRAVITY       USER-GROUP     ANNUALLY   \n",
       "1              2010                GRAVITY       USER-GROUP    NEVER PAY   \n",
       "2              2009                GRAVITY       USER-GROUP   PER BUCKET   \n",
       "3              1986            SUBMERSIBLE       USER-GROUP    NEVER PAY   \n",
       "4                 0                GRAVITY            OTHER    NEVER PAY   \n",
       "\n",
       "  quality_group      quantity source_class              waterpoint_type  \\\n",
       "0          GOOD        ENOUGH  GROUNDWATER           COMMUNAL STANDPIPE   \n",
       "1          GOOD  INSUFFICIENT      SURFACE           COMMUNAL STANDPIPE   \n",
       "2          GOOD        ENOUGH      SURFACE  COMMUNAL STANDPIPE MULTIPLE   \n",
       "3          GOOD           DRY  GROUNDWATER  COMMUNAL STANDPIPE MULTIPLE   \n",
       "4          GOOD      SEASONAL      SURFACE           COMMUNAL STANDPIPE   \n",
       "\n",
       "     status_group year_recorded  \n",
       "0      FUNCTIONAL          2011  \n",
       "1      FUNCTIONAL          2013  \n",
       "2      FUNCTIONAL          2013  \n",
       "3  NON FUNCTIONAL          2013  \n",
       "4      FUNCTIONAL          2011  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"./data/wells_data_cleaned.csv\")\n",
    "df_valid = pd.read_csv(\"./data/validataion_data_cleaned.csv\")\n",
    "\n",
    "# Check the first few rows to confirm the structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FUNCTIONAL', 'NON FUNCTIONAL', 'FUNCTIONAL NEEDS REPAIR'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['status_group'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Recatecorize Target Variable to Binary class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functional -> 0 , Non-functional -> 1 , Function needs repir ->1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Target Variable Distribution:\n",
      "0    32259\n",
      "1    27141\n",
      "Name: status_group_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def recategorize_target_variable(df, target_column, new_column):\n",
    "   \n",
    "    df[new_column] = df[target_column].apply(lambda x: 0 if x == 'FUNCTIONAL' else 1)\n",
    "    return df\n",
    "\n",
    "# Application for recategorizing target variable\n",
    "data = recategorize_target_variable(df, target_column='status_group', new_column='status_group_binary')\n",
    "print(\"Binary Target Variable Distribution:\")\n",
    "print(data['status_group_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Splitting Data ###\n",
      "Training set size: 47520 rows\n",
      "Testing set size: 11880 rows\n",
      "\n",
      "### Encoding Categorical and Boolean Columns with Balanced Approach ###\n",
      "Boolean columns: []\n",
      "Categorical columns: ['funder', 'installer', 'basin', 'region', 'lga', 'public_meeting', 'scheme_management', 'permit', 'extraction_type_class', 'management_group', 'payment_type', 'quality_group', 'quantity', 'source_class', 'waterpoint_type']\n",
      "Balanced encoding completed successfully.\n",
      "Target Encoding Mapping:\n",
      "{0: 0, 1: 1}\n",
      "Data processing completed successfully.\n",
      "Processed training and testing data are ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"./data/binary_clf_data.csv\")\n",
    "\n",
    "# Initialize DataProcessor\n",
    "processor = DataProcessor(df, target_column=\"status_group_binary\")\n",
    "\n",
    "# Process the data\n",
    "processor.process_data()\n",
    "\n",
    "# Access processed data\n",
    "X_train = processor.X_train\n",
    "X_test = processor.X_test\n",
    "y_train = processor.y_train_encoded\n",
    "y_test = processor.y_test_encoded\n",
    "\n",
    "# Save components for reuse in validation data processing\n",
    "reference_columns = processor.X_train.columns.tolist()\n",
    "training_label_encoders = processor.label_encoders\n",
    "training_scaler = processor.scaler\n",
    "\n",
    "print(\"Processed training and testing data are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import modules.testprocessor\n",
    "reload(modules.testprocessor)\n",
    "from modules.testprocessor import TestDatasetProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import json\n",
    "\n",
    "# # Load reference columns from training\n",
    "# with open(\"columns.json\", \"r\") as file:\n",
    "#     reference_columns = json.load(file)\n",
    "\n",
    "# # Load validation dataset\n",
    "# validation_df = pd.read_csv(\"./data/validataion_data_cleaned.csv\")\n",
    "\n",
    "# # Check validation dataset columns\n",
    "# print(\"Validation Data Columns Before Processing:\", validation_df.columns.tolist())\n",
    "# print(\"Reference Columns (Training):\", reference_columns)\n",
    "\n",
    "# # Align validation data columns with reference columns\n",
    "# validation_df = validation_df.reindex(columns=reference_columns, fill_value=0)\n",
    "\n",
    "# # Initialize and process validation data\n",
    "# test_processor = TestDatasetProcessor(\n",
    "#     dataframe=validation_df,\n",
    "#     reference_columns=reference_columns,\n",
    "#     training_label_encoders=training_label_encoders,\n",
    "#     training_scaler=training_scaler\n",
    "# )\n",
    "\n",
    "# # Process the validation data\n",
    "# try:\n",
    "#     test_processor.process_data()\n",
    "# except Exception as e:\n",
    "#     print(\"Error during processing validation data:\", e)\n",
    "\n",
    "# # Access processed validation data\n",
    "# processed_validation_X = test_processor.processed_X\n",
    "\n",
    "# # Check processed validation data\n",
    "# print(\"Processed Validation Data Columns:\", processed_validation_X.columns.tolist())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.0 Fitting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Dummy Classifier as the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Accuracy: 0.4968013468013468\n",
      "\n",
      "Classification Report for Dummy Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54      6457\n",
      "           1       0.45      0.44      0.45      5423\n",
      "\n",
      "    accuracy                           0.50     11880\n",
      "   macro avg       0.49      0.49      0.49     11880\n",
      "weighted avg       0.50      0.50      0.50     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Initialize the dummy classifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)  # Predicts according to the training setâ€™s class distribution\n",
    "\n",
    "# Train the dummy classifier\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Dummy Classifier Accuracy:\", accuracy_score(y_test, y_pred_dummy))\n",
    "print(\"\\nClassification Report for Dummy Classifier:\")\n",
    "print(classification_report(y_test, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our dummy classifier with its limitation of using class distribution produced an 50% accuracy. It will act as our baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6876262626262626\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73      6457\n",
      "           1       0.69      0.58      0.63      5423\n",
      "\n",
      "    accuracy                           0.69     11880\n",
      "   macro avg       0.69      0.68      0.68     11880\n",
      "weighted avg       0.69      0.69      0.68     11880\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "regr = LogisticRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7819023569023569\n",
      "\n",
      "Classification Report for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      6457\n",
      "           1       0.76      0.76      0.76      5423\n",
      "\n",
      "    accuracy                           0.78     11880\n",
      "   macro avg       0.78      0.78      0.78     11880\n",
      "weighted avg       0.78      0.78      0.78     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree classifier\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the Decision Tree\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_decision_tree))\n",
    "print(\"\\nClassification Report for Decision Tree:\")\n",
    "print(classification_report(y_test, y_pred_decision_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8181818181818182\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      6457\n",
      "           1       0.82      0.77      0.80      5423\n",
      "\n",
      "    accuracy                           0.82     11880\n",
      "   macro avg       0.82      0.81      0.82     11880\n",
      "weighted avg       0.82      0.82      0.82     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_random_forest))\n",
    "print(\"\\nClassification Report for Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Observations:**\n",
    "- The `Random Forest` significantly outperforms the `Decision Tree` and `Logistic Regression` in both accuracy and F1-scores.\n",
    "- It maintains a good balance across both classes.\n",
    "- `Precision` and `Recall` for Class 0 (Functional) and Class 1 (Non-functional/Needs Repair) are more robust, making this model the most reliable so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Feature  Importance\n",
      "4               longitude    0.144291\n",
      "5                latitude    0.143124\n",
      "2              gps_height    0.071258\n",
      "12      construction_year    0.058459\n",
      "1                  funder    0.050638\n",
      "8              population    0.048370\n",
      "43        quantity_ENOUGH    0.045823\n",
      "3               installer    0.042954\n",
      "7                     lga    0.035378\n",
      "54  waterpoint_type_OTHER    0.033875\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Features and Their Importance:\n",
    "\n",
    " *longitude (14.43%) and latitude (14.31%):*\n",
    "- These spatial features play a significant role, indicating that the location of a well strongly influences its functionality.\n",
    "- Potential reasons include regional differences in water table levels, terrain, or management practices.\n",
    "\n",
    " *gps_height (7.13%):*\n",
    "- The elevation of the well likely impacts water availability, as higher elevations might face challenges in accessing groundwater.\n",
    "\n",
    " *construction_year (5.85%):*\n",
    "- Older wells may be more prone to failures or require more repairs due to wear and tear over time.\n",
    "\n",
    " *funder (5.06%):*\n",
    "- The organization funding the well influences its quality and durability, as some funders might use better construction standards.\n",
    "\n",
    " *population (4.84%):*\n",
    "- Larger populations might lead to overuse of wells, increasing the chances of failure or repair needs.\n",
    "\n",
    " *quantity_ENOUGH (4.58%):*\n",
    "- This feature suggests whether the well provides sufficient water, a direct indicator of functionality.\n",
    "\n",
    " *installer (4.30%):* \n",
    "- The party installing the well impacts its reliability, likely reflecting variations in expertise or materials used.\n",
    "\n",
    " *lga (3.54%):*\n",
    "- The Local Government Area (LGA) might reflect regional policies, maintenance, or socio-economic factors affecting well functionality.\n",
    "\n",
    " *waterpoint_type_OTHER (3.38%):*\n",
    "- The type of waterpoint influences its reliability, with some types being more prone to failure than others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Hyperparameter Tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],  # Depth of trees\n",
    "    'min_samples_split': [2, 5, 10],  # Min samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Min samples at a leaf node\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='accuracy',  # Evaluate using accuracy\n",
    "    verbose=2,  # Show progress\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Cross-Validation Accuracy: 0.8187710437710437\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best score from GridSearchCV\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6 Training and Evaluating the Best Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (Best Model): 0.8247474747474748\n",
      "\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84      6457\n",
      "           1       0.84      0.76      0.80      5423\n",
      "\n",
      "    accuracy                           0.82     11880\n",
      "   macro avg       0.83      0.82      0.82     11880\n",
      "weighted avg       0.83      0.82      0.82     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the best Random Forest model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Random Forest Accuracy (Best Model):\", accuracy_score(y_test, y_pred_best_rf))\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7 Validating the Model with an entirely new dataset(Test data dowloaded from taarifa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for Validation Data:\n",
      "[0 0 1 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "validation_predictions = best_rf.predict(processed_validation_X)\n",
    "\n",
    "# Output the predictions\n",
    "print(\"Predictions for Validation Data:\")\n",
    "print(validation_predictions[:10])  # Display the first 10 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution of Predictions:\n",
      "1    0.780337\n",
      "0    0.219663\n",
      "Name: Prediction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Convert predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(validation_predictions, columns=[\"Prediction\"])\n",
    "\n",
    "# Analyze the distribution of predictions\n",
    "class_distribution = predictions_df[\"Prediction\"].value_counts(normalize=True)\n",
    "print(\"Class Distribution of Predictions:\")\n",
    "print(class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in Training Data:\n",
      "0    0.542971\n",
      "1    0.457029\n",
      "Name: status_group_binary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Distribution in training data\n",
    "training_class_distribution = pd.Series(y_train).value_counts(normalize=True)\n",
    "print(\"Class Distribution in Training Data:\")\n",
    "print(training_class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: amount_tsh\n",
      "Training Mean: -7.924824283519636e-18 Validation Mean: 1.2440478875261014e-17\n",
      "Feature: funder\n",
      "Training Mean: 793.3220538720539 Validation Mean: 0.0\n",
      "Feature: gps_height\n",
      "Training Mean: -3.947459643111668e-17 Validation Mean: 6.315935428978668e-17\n",
      "Feature: installer\n",
      "Training Mean: 685.2946548821549 Validation Mean: 0.0\n",
      "Feature: longitude\n",
      "Training Mean: 6.836282381934297e-16 Validation Mean: -4.732166772166593e-16\n",
      "Feature: latitude\n",
      "Training Mean: 3.367302695563438e-16 Validation Mean: -5.7417594808896985e-18\n",
      "Feature: region\n",
      "Training Mean: 9.832112794612794 Validation Mean: 0.0\n",
      "Feature: lga\n",
      "Training Mean: 60.0641835016835 Validation Mean: 0.0\n",
      "Feature: population\n",
      "Training Mean: 8.373399242964143e-18 Validation Mean: 9.569599134816163e-19\n",
      "Feature: public_meeting\n",
      "Training Mean: 0.9081860269360269 Validation Mean: 0.9067340067340067\n",
      "Feature: scheme_management\n",
      "Training Mean: 7.281986531986532 Validation Mean: 0.0\n",
      "Feature: permit\n",
      "Training Mean: 0.7012626262626263 Validation Mean: 0.7026262626262626\n",
      "Feature: construction_year\n",
      "Training Mean: -3.184882212056005e-17 Validation Mean: 1.1292126979083073e-16\n",
      "Feature: year_recorded\n",
      "Training Mean: 6.426225059007425e-14 Validation Mean: -3.607212545873279e-14\n",
      "Feature: basin_LAKE NYASA\n",
      "Training Mean: 0.08446969696969697 Validation Mean: 0.0\n",
      "Feature: basin_LAKE RUKWA\n",
      "Training Mean: 0.04179292929292929 Validation Mean: 0.0\n",
      "Feature: basin_LAKE TANGANYIKA\n",
      "Training Mean: 0.10877525252525252 Validation Mean: 0.0\n",
      "Feature: basin_LAKE VICTORIA\n",
      "Training Mean: 0.1726641414141414 Validation Mean: 0.0\n",
      "Feature: basin_PANGANI\n",
      "Training Mean: 0.15031565656565657 Validation Mean: 0.0\n",
      "Feature: basin_RUFIJI\n",
      "Training Mean: 0.13415404040404041 Validation Mean: 0.0\n",
      "Feature: basin_RUVUMA / SOUTHERN COAST\n",
      "Training Mean: 0.07575757575757576 Validation Mean: 0.0\n",
      "Feature: basin_WAMI / RUVU\n",
      "Training Mean: 0.1010942760942761 Validation Mean: 0.0\n",
      "Feature: extraction_type_class_HANDPUMP\n",
      "Training Mean: 0.27824074074074073 Validation Mean: 0.0\n",
      "Feature: extraction_type_class_MOTORPUMP\n",
      "Training Mean: 0.05021043771043771 Validation Mean: 0.0\n",
      "Feature: extraction_type_class_OTHER\n",
      "Training Mean: 0.10837542087542087 Validation Mean: 0.0\n",
      "Feature: extraction_type_class_ROPE PUMP\n",
      "Training Mean: 0.007912457912457913 Validation Mean: 0.0\n",
      "Feature: extraction_type_class_SUBMERSIBLE\n",
      "Training Mean: 0.10441919191919193 Validation Mean: 0.0\n",
      "Feature: extraction_type_class_WIND-POWERED\n",
      "Training Mean: 0.0017676767676767678 Validation Mean: 0.0\n",
      "Feature: management_group_OTHER\n",
      "Training Mean: 0.016077441077441076 Validation Mean: 0.0\n",
      "Feature: management_group_PARASTATAL\n",
      "Training Mean: 0.029734848484848486 Validation Mean: 0.0\n",
      "Feature: management_group_UNKNOWN\n",
      "Training Mean: 0.009595959595959595 Validation Mean: 0.0\n",
      "Feature: management_group_USER-GROUP\n",
      "Training Mean: 0.8842171717171717 Validation Mean: 0.0\n",
      "Feature: payment_type_MONTHLY\n",
      "Training Mean: 0.13834175084175085 Validation Mean: 0.0\n",
      "Feature: payment_type_NEVER PAY\n",
      "Training Mean: 0.42756734006734004 Validation Mean: 0.0\n",
      "Feature: payment_type_ON FAILURE\n",
      "Training Mean: 0.06637205387205387 Validation Mean: 0.0\n",
      "Feature: payment_type_OTHER\n",
      "Training Mean: 0.017760942760942762 Validation Mean: 0.0\n",
      "Feature: payment_type_PER BUCKET\n",
      "Training Mean: 0.15199915824915824 Validation Mean: 0.0\n",
      "Feature: payment_type_UNKNOWN\n",
      "Training Mean: 0.13722643097643097 Validation Mean: 0.0\n",
      "Feature: quality_group_FLUORIDE\n",
      "Training Mean: 0.003766835016835017 Validation Mean: 0.0\n",
      "Feature: quality_group_GOOD\n",
      "Training Mean: 0.8550715488215488 Validation Mean: 0.0\n",
      "Feature: quality_group_MILKY\n",
      "Training Mean: 0.013678451178451179 Validation Mean: 0.0\n",
      "Feature: quality_group_SALTY\n",
      "Training Mean: 0.08781565656565657 Validation Mean: 0.0\n",
      "Feature: quality_group_UNKNOWN\n",
      "Training Mean: 0.03135521885521886 Validation Mean: 0.0\n",
      "Feature: quantity_ENOUGH\n",
      "Training Mean: 0.5584595959595959 Validation Mean: 0.0\n",
      "Feature: quantity_INSUFFICIENT\n",
      "Training Mean: 0.2547138047138047 Validation Mean: 0.0\n",
      "Feature: quantity_SEASONAL\n",
      "Training Mean: 0.06786616161616162 Validation Mean: 0.0\n",
      "Feature: quantity_UNKNOWN\n",
      "Training Mean: 0.013236531986531987 Validation Mean: 0.0\n",
      "Feature: source_class_SURFACE\n",
      "Training Mean: 0.22430555555555556 Validation Mean: 0.0\n",
      "Feature: source_class_UNKNOWN\n",
      "Training Mean: 0.004924242424242424 Validation Mean: 0.0\n",
      "Feature: waterpoint_type_COMMUNAL STANDPIPE\n",
      "Training Mean: 0.47948232323232326 Validation Mean: 0.0\n",
      "Feature: waterpoint_type_COMMUNAL STANDPIPE MULTIPLE\n",
      "Training Mean: 0.10164141414141414 Validation Mean: 0.0\n",
      "Feature: waterpoint_type_DAM\n",
      "Training Mean: 8.417508417508418e-05 Validation Mean: 0.0\n",
      "Feature: waterpoint_type_HAND PUMP\n",
      "Training Mean: 0.2961489898989899 Validation Mean: 0.0\n",
      "Feature: waterpoint_type_IMPROVED SPRING\n",
      "Training Mean: 0.013446969696969697 Validation Mean: 0.0\n",
      "Feature: waterpoint_type_OTHER\n",
      "Training Mean: 0.10728114478114478 Validation Mean: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Compare distributions for key features\n",
    "for col in processed_validation_X.columns:\n",
    "    print(f\"Feature: {col}\")\n",
    "    print(\"Training Mean:\", X_train[col].mean(), \"Validation Mean:\", processed_validation_X[col].mean())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
