{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BINARY CLASSIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Feature selection and engineering\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "#Model evaluation\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory of 'modules' to sys.path\n",
    "sys.path.append(os.path.abspath(\"../modules\"))\n",
    "\n",
    "# Now import\n",
    "from modules.EDA import EDA\n",
    "from modules.dataprocessor import DataProcessor\n",
    "from modules.testprocessor import TestDatasetProcessor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.0 Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>date_recorded</th>\n",
       "      <th>funder</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>installer</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>...</th>\n",
       "      <th>construction_year</th>\n",
       "      <th>extraction_type_class</th>\n",
       "      <th>management_group</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>status_group</th>\n",
       "      <th>year_recorded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>2011-03-14</td>\n",
       "      <td>ROMAN</td>\n",
       "      <td>1390.0</td>\n",
       "      <td>ROMAN</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>LAKE NYASA</td>\n",
       "      <td>IRINGA</td>\n",
       "      <td>...</td>\n",
       "      <td>1999</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>ANNUALLY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>ENOUGH</td>\n",
       "      <td>GROUNDWATER</td>\n",
       "      <td>COMMUNAL STANDPIPE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-03-06</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>GRUMETI</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>LAKE VICTORIA</td>\n",
       "      <td>MARA</td>\n",
       "      <td>...</td>\n",
       "      <td>2010</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>NEVER PAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>INSUFFICIENT</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COMMUNAL STANDPIPE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2013-02-25</td>\n",
       "      <td>LOTTERY CLUB</td>\n",
       "      <td>686.0</td>\n",
       "      <td>WORLD VISION</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>PANGANI</td>\n",
       "      <td>MANYARA</td>\n",
       "      <td>...</td>\n",
       "      <td>2009</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>PER BUCKET</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>ENOUGH</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COMMUNAL STANDPIPE MULTIPLE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2013-01-28</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>263.0</td>\n",
       "      <td>UNICEF</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>RUVUMA / SOUTHERN COAST</td>\n",
       "      <td>MTWARA</td>\n",
       "      <td>...</td>\n",
       "      <td>1986</td>\n",
       "      <td>SUBMERSIBLE</td>\n",
       "      <td>USER-GROUP</td>\n",
       "      <td>NEVER PAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>DRY</td>\n",
       "      <td>GROUNDWATER</td>\n",
       "      <td>COMMUNAL STANDPIPE MULTIPLE</td>\n",
       "      <td>NON FUNCTIONAL</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2011-07-13</td>\n",
       "      <td>ACTION IN A</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ARTISAN</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>LAKE VICTORIA</td>\n",
       "      <td>KAGERA</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>GRAVITY</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>NEVER PAY</td>\n",
       "      <td>GOOD</td>\n",
       "      <td>SEASONAL</td>\n",
       "      <td>SURFACE</td>\n",
       "      <td>COMMUNAL STANDPIPE</td>\n",
       "      <td>FUNCTIONAL</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n",
       "0  69572      6000.0    2011-03-14         ROMAN      1390.0         ROMAN   \n",
       "1   8776         0.0    2013-03-06       GRUMETI      1399.0       GRUMETI   \n",
       "2  34310        25.0    2013-02-25  LOTTERY CLUB       686.0  WORLD VISION   \n",
       "3  67743         0.0    2013-01-28        UNICEF       263.0        UNICEF   \n",
       "4  19728         0.0    2011-07-13   ACTION IN A         0.0       ARTISAN   \n",
       "\n",
       "   longitude   latitude                    basin   region  ...  \\\n",
       "0  34.938093  -9.856322               LAKE NYASA   IRINGA  ...   \n",
       "1  34.698766  -2.147466            LAKE VICTORIA     MARA  ...   \n",
       "2  37.460664  -3.821329                  PANGANI  MANYARA  ...   \n",
       "3  38.486161 -11.155298  RUVUMA / SOUTHERN COAST   MTWARA  ...   \n",
       "4  31.130847  -1.825359            LAKE VICTORIA   KAGERA  ...   \n",
       "\n",
       "  construction_year  extraction_type_class management_group payment_type  \\\n",
       "0              1999                GRAVITY       USER-GROUP     ANNUALLY   \n",
       "1              2010                GRAVITY       USER-GROUP    NEVER PAY   \n",
       "2              2009                GRAVITY       USER-GROUP   PER BUCKET   \n",
       "3              1986            SUBMERSIBLE       USER-GROUP    NEVER PAY   \n",
       "4                 0                GRAVITY            OTHER    NEVER PAY   \n",
       "\n",
       "  quality_group      quantity source_class              waterpoint_type  \\\n",
       "0          GOOD        ENOUGH  GROUNDWATER           COMMUNAL STANDPIPE   \n",
       "1          GOOD  INSUFFICIENT      SURFACE           COMMUNAL STANDPIPE   \n",
       "2          GOOD        ENOUGH      SURFACE  COMMUNAL STANDPIPE MULTIPLE   \n",
       "3          GOOD           DRY  GROUNDWATER  COMMUNAL STANDPIPE MULTIPLE   \n",
       "4          GOOD      SEASONAL      SURFACE           COMMUNAL STANDPIPE   \n",
       "\n",
       "     status_group year_recorded  \n",
       "0      FUNCTIONAL          2011  \n",
       "1      FUNCTIONAL          2013  \n",
       "2      FUNCTIONAL          2013  \n",
       "3  NON FUNCTIONAL          2013  \n",
       "4      FUNCTIONAL          2011  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"./data/wells_data_cleaned.csv\")\n",
    "df_valid = pd.read_csv(\"./data/validataion_data_cleaned.csv\")\n",
    "\n",
    "# Check the first few rows to confirm the structure\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Recatecorize Target Variable to Binary class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Functional -> 0 , Non-functional -> 1 , Function needs repir ->1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Target Variable Distribution:\n",
      "0    32259\n",
      "1    27141\n",
      "Name: status_group_binary, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def recategorize_target_variable(df, target_column, new_column):\n",
    "   \n",
    "    df[new_column] = df[target_column].apply(lambda x: 0 if x == 'FUNCTIONAL' else 1)\n",
    "    return df\n",
    "\n",
    "# Application for recategorizing target variable\n",
    "data = recategorize_target_variable(df, target_column='status_group', new_column='status_group_binary')\n",
    "print(\"Binary Target Variable Distribution:\")\n",
    "print(data['status_group_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe to be used in binary classification\n",
    "df1 = df.drop('status_group',axis = 1)\n",
    "df1.to_csv ('./data/binary_clf_data.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Splitting Data ###\n",
      "Training set size: 47520 rows\n",
      "Testing set size: 11880 rows\n",
      "\n",
      "### Encoding Categorical and Boolean Columns with Balanced Approach ###\n",
      "Boolean columns: ['public_meeting', 'permit']\n",
      "Categorical columns: ['funder', 'installer', 'basin', 'region', 'lga', 'scheme_management', 'extraction_type_class', 'management_group', 'payment_type', 'quality_group', 'quantity', 'source_class', 'waterpoint_type']\n",
      "Balanced encoding completed successfully.\n",
      "Target Encoding Mapping:\n",
      "{0: 0, 1: 1}\n",
      "Data processing completed successfully.\n",
      "Processed training and testing data are ready.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"./data/binary_clf_data.csv\")\n",
    "\n",
    "# Initialize DataProcessor\n",
    "processor = DataProcessor(df, target_column=\"status_group_binary\")\n",
    "\n",
    "# Process the data\n",
    "processor.process_data()\n",
    "\n",
    "# Access processed data\n",
    "X_train = processor.X_train\n",
    "X_test = processor.X_test\n",
    "y_train = processor.y_train_encoded\n",
    "y_test = processor.y_test_encoded\n",
    "\n",
    "print(\"Processed training and testing data are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Encoding Categorical and Boolean Columns ###\n",
      "Boolean columns: ['public_meeting', 'permit']\n",
      "Categorical columns: ['date_recorded', 'funder', 'installer', 'basin', 'region', 'lga', 'scheme_management', 'extraction_type_class', 'management_group', 'payment_type', 'quality_group', 'quantity', 'source_class', 'waterpoint_type']\n",
      "Balanced encoding completed successfully.\n",
      "Test dataset processing completed successfully.\n",
      "Processed Validation Data (first 5 rows):\n",
      "   amount_tsh  funder  gps_height  installer  longitude  latitude  region  \\\n",
      "0   -0.128571     0.0    1.942225        0.0   0.081843  0.552598     0.0   \n",
      "1   -0.128571     0.0    1.321841        0.0   0.607162  0.807803     0.0   \n",
      "2   -0.128571     0.0    1.318935        0.0  -0.119274  0.231366     0.0   \n",
      "3   -0.128571     0.0   -0.569821        0.0   1.146105 -1.269746     0.0   \n",
      "4    0.070562     0.0    0.872898        0.0  -0.027641 -1.790621     0.0   \n",
      "\n",
      "   lga  population  public_meeting  ...  quantity_SEASONAL  quantity_UNKNOWN  \\\n",
      "0  0.0    0.288252               1  ...                0.0               0.0   \n",
      "1  0.0    0.243475               1  ...                0.0               0.0   \n",
      "2  0.0    0.669919               1  ...                0.0               0.0   \n",
      "3  0.0    0.136864               1  ...                0.0               0.0   \n",
      "4  0.0   -0.268257               1  ...                0.0               0.0   \n",
      "\n",
      "   source_class_SURFACE  source_class_UNKNOWN  \\\n",
      "0                   0.0                   0.0   \n",
      "1                   0.0                   0.0   \n",
      "2                   0.0                   0.0   \n",
      "3                   0.0                   0.0   \n",
      "4                   0.0                   0.0   \n",
      "\n",
      "   waterpoint_type_COMMUNAL STANDPIPE  \\\n",
      "0                                 0.0   \n",
      "1                                 0.0   \n",
      "2                                 0.0   \n",
      "3                                 0.0   \n",
      "4                                 0.0   \n",
      "\n",
      "   waterpoint_type_COMMUNAL STANDPIPE MULTIPLE  waterpoint_type_DAM  \\\n",
      "0                                          0.0                  0.0   \n",
      "1                                          0.0                  0.0   \n",
      "2                                          0.0                  0.0   \n",
      "3                                          0.0                  0.0   \n",
      "4                                          0.0                  0.0   \n",
      "\n",
      "   waterpoint_type_HAND PUMP  waterpoint_type_IMPROVED SPRING  \\\n",
      "0                        0.0                              0.0   \n",
      "1                        0.0                              0.0   \n",
      "2                        0.0                              0.0   \n",
      "3                        0.0                              0.0   \n",
      "4                        0.0                              0.0   \n",
      "\n",
      "   waterpoint_type_OTHER  \n",
      "0                    0.0  \n",
      "1                    0.0  \n",
      "2                    0.0  \n",
      "3                    0.0  \n",
      "4                    0.0  \n",
      "\n",
      "[5 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load reference columns from training\n",
    "with open(\"columns.json\", \"r\") as file:\n",
    "    reference_columns = json.load(file)\n",
    "\n",
    "# Load new test dataset\n",
    "validation_df = pd.read_csv(\"./data/validataion_data_cleaned.csv\")\n",
    "\n",
    "# Initialize and process the dataset\n",
    "test_processor = TestDatasetProcessor(validation_df, reference_columns)\n",
    "test_processor.process_data()\n",
    "\n",
    "# Access the processed data\n",
    "processed_validation_X = test_processor.processed_X\n",
    "\n",
    "# Display processed dataset\n",
    "print(\"Processed Validation Data (first 5 rows):\")\n",
    "print(processed_validation_X.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.0 Fitting Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Dummy Classifier as the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier Accuracy: 0.4968013468013468\n",
      "\n",
      "Classification Report for Dummy Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.54      0.54      6457\n",
      "           1       0.45      0.44      0.45      5423\n",
      "\n",
      "    accuracy                           0.50     11880\n",
      "   macro avg       0.49      0.49      0.49     11880\n",
      "weighted avg       0.50      0.50      0.50     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "# Initialize the dummy classifier\n",
    "dummy_clf = DummyClassifier(strategy=\"stratified\", random_state=42)  # Predicts according to the training set’s class distribution\n",
    "\n",
    "# Train the dummy classifier\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_dummy = dummy_clf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"Dummy Classifier Accuracy:\", accuracy_score(y_test, y_pred_dummy))\n",
    "print(\"\\nClassification Report for Dummy Classifier:\")\n",
    "print(classification_report(y_test, y_pred_dummy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our dummy classifier with its limitation of using class distribution produced an 50% accuracy. It will act as our baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6876262626262626\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.78      0.73      6457\n",
      "           1       0.69      0.58      0.63      5423\n",
      "\n",
      "    accuracy                           0.69     11880\n",
      "   macro avg       0.69      0.68      0.68     11880\n",
      "weighted avg       0.69      0.69      0.68     11880\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADMIN\\anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression\n",
    "regr = LogisticRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.7819023569023569\n",
      "\n",
      "Classification Report for Decision Tree:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      6457\n",
      "           1       0.76      0.76      0.76      5423\n",
      "\n",
      "    accuracy                           0.78     11880\n",
      "   macro avg       0.78      0.78      0.78     11880\n",
      "weighted avg       0.78      0.78      0.78     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Decision Tree classifier\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the Decision Tree classifier\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_decision_tree = decision_tree.predict(X_test)\n",
    "\n",
    "# Evaluate the Decision Tree\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_decision_tree))\n",
    "print(\"\\nClassification Report for Decision Tree:\")\n",
    "print(classification_report(y_test, y_pred_decision_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8181818181818182\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      6457\n",
      "           1       0.82      0.77      0.80      5423\n",
      "\n",
      "    accuracy                           0.82     11880\n",
      "   macro avg       0.82      0.81      0.82     11880\n",
      "weighted avg       0.82      0.82      0.82     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "random_forest = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the Random Forest classifier\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "\n",
    "# Evaluate the Random Forest\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_random_forest))\n",
    "print(\"\\nClassification Report for Random Forest:\")\n",
    "print(classification_report(y_test, y_pred_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Observations:**\n",
    "- The `Random Forest` significantly outperforms the `Decision Tree` and `Logistic Regression` in both accuracy and F1-scores.\n",
    "- It maintains a good balance across both classes.\n",
    "- `Precision` and `Recall` for Class 0 (Functional) and Class 1 (Non-functional/Needs Repair) are more robust, making this model the most reliable so far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Feature  Importance\n",
      "4               longitude    0.144291\n",
      "5                latitude    0.143124\n",
      "2              gps_height    0.071258\n",
      "12      construction_year    0.058459\n",
      "1                  funder    0.050638\n",
      "8              population    0.048370\n",
      "43        quantity_ENOUGH    0.045823\n",
      "3               installer    0.042954\n",
      "7                     lga    0.035378\n",
      "54  waterpoint_type_OTHER    0.033875\n"
     ]
    }
   ],
   "source": [
    "# Extract feature importance\n",
    "feature_importances = random_forest.feature_importances_\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the top features\n",
    "print(importance_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Features and Their Importance:\n",
    "\n",
    " *longitude (14.43%) and latitude (14.31%):*\n",
    "- These spatial features play a significant role, indicating that the location of a well strongly influences its functionality.\n",
    "- Potential reasons include regional differences in water table levels, terrain, or management practices.\n",
    "\n",
    " *gps_height (7.13%):*\n",
    "- The elevation of the well likely impacts water availability, as higher elevations might face challenges in accessing groundwater.\n",
    "\n",
    " *construction_year (5.85%):*\n",
    "- Older wells may be more prone to failures or require more repairs due to wear and tear over time.\n",
    "\n",
    " *funder (5.06%):*\n",
    "- The organization funding the well influences its quality and durability, as some funders might use better construction standards.\n",
    "\n",
    " *population (4.84%):*\n",
    "- Larger populations might lead to overuse of wells, increasing the chances of failure or repair needs.\n",
    "\n",
    " *quantity_ENOUGH (4.58%):*\n",
    "- This feature suggests whether the well provides sufficient water, a direct indicator of functionality.\n",
    "\n",
    " *installer (4.30%):* \n",
    "- The party installing the well impacts its reliability, likely reflecting variations in expertise or materials used.\n",
    "\n",
    " *lga (3.54%):*\n",
    "- The Local Government Area (LGA) might reflect regional policies, maintenance, or socio-economic factors affecting well functionality.\n",
    "\n",
    " *waterpoint_type_OTHER (3.38%):*\n",
    "- The type of waterpoint influences its reliability, with some types being more prone to failure than others.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 Hyperparameter Tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'max_depth': [None, 10, 20, 30],  # Depth of trees\n",
    "    'min_samples_split': [2, 5, 10],  # Min samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4]     # Min samples at a leaf node\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [100, 200, 300]},\n",
       "             scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(random_state=42), n_jobs=-1,\n",
       "             param_grid={'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [100, 200, 300]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    scoring='accuracy',  # Evaluate using accuracy\n",
    "    verbose=2,  # Show progress\n",
    "    n_jobs=-1  # Use all processors\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'max_depth': 20, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best Cross-Validation Accuracy: 0.8187710437710437\n"
     ]
    }
   ],
   "source": [
    "# Best hyperparameters\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Best score from GridSearchCV\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.6 Training and Evaluating the Best Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy (Best Model): 0.8247474747474748\n",
      "\n",
      "Classification Report (Best Model):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84      6457\n",
      "           1       0.84      0.76      0.80      5423\n",
      "\n",
      "    accuracy                           0.82     11880\n",
      "   macro avg       0.83      0.82      0.82     11880\n",
      "weighted avg       0.83      0.82      0.82     11880\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the best Random Forest model\n",
    "best_rf = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "print(\"Random Forest Accuracy (Best Model):\", accuracy_score(y_test, y_pred_best_rf))\n",
    "print(\"\\nClassification Report (Best Model):\")\n",
    "print(classification_report(y_test, y_pred_best_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.7 Validating the Model with an entirely new dataset(Test data dowloaded from taarifa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for Validation Data:\n",
      "[0 0 1 1 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Predict on the validation set\n",
    "validation_predictions = best_rf.predict(processed_validation_X)\n",
    "\n",
    "# Output the predictions\n",
    "print(\"Predictions for Validation Data:\")\n",
    "print(validation_predictions[:10])  # Display the first 10 predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution of Predictions:\n",
      "1    0.780337\n",
      "0    0.219663\n",
      "Name: Prediction, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Convert predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(validation_predictions, columns=[\"Prediction\"])\n",
    "\n",
    "# Analyze the distribution of predictions\n",
    "class_distribution = predictions_df[\"Prediction\"].value_counts(normalize=True)\n",
    "print(\"Class Distribution of Predictions:\")\n",
    "print(class_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution in Training Data:\n",
      "0    0.542971\n",
      "1    0.457029\n",
      "Name: status_group_binary, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Distribution in training data\n",
    "training_class_distribution = pd.Series(y_train).value_counts(normalize=True)\n",
    "print(\"Class Distribution in Training Data:\")\n",
    "print(training_class_distribution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
